{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Replication of Gianattasio et al. (2019)\"\n",
        "author: \"Ralph Møller Trane\"\n",
        "format: \n",
        "  gfm:\n",
        "    output-file: README.md\n",
        "bibliography: references.bib\n",
        "editor_options: \n",
        "  chunk_output_type: console\n",
        "engine: jupyter\n",
        "---\n",
        "\n",
        "\n",
        "## Introduction\n",
        "\n",
        "This repo aims at replicating the results of @gianattasioComparisonMethodsAlgorithmic2019. The greater idea behind this is a desire to implement the algorithms in R for future research purposes, specifically validating the main findings from @gianattasioComparisonMethodsAlgorithmic2019 by way of analyzing WLS data. To that end, we want to ensure that our implementation of the algorithms are aligned with previous implementations. Therefore, we create this pipeline with instructions to recreate the training and validation datasets from @gianattasioComparisonMethodsAlgorithmic2019 that can serve to ensure the correctness of our implementations of algorithms.\n",
        "\n",
        "## Requirments\n",
        "\n",
        "This repo was developed for use on a linux machine with a working installation of R and SAS available. We provide a `Makefile` to easily recreate the training and validation datasets. The main pieces of software used are \n",
        "\n",
        "* `SAS` version 9.4 with analytical products\n",
        "    * `SAS/STAT 15.3`\n",
        "    * `SAS/ETS 15.3`\n",
        "    * `SAS/OR 15.3`\n",
        "    * `SAS/IML 15.3`\n",
        "    * `SAS/QC 15.3`\n",
        "* `R 4.4.0` with the following packages installed:\n",
        "    * `haven` version `2.5.4`\n",
        "    * `readr` version `2.1.5` \n",
        "    * `tidyr` version `1.3.1` \n",
        "    * Things will most likely also work with previous versions\n",
        "* `Make` version `4.2.1`\n",
        "\n",
        "## Step-by-step guide\n",
        "\n",
        "We will go through the creation of the validation and test datasets step-by-step below. However, to simply quickly and easily create the data files, you can clone this repo to your local machine, download the files mentioned below to the folder `data/HRS-zips`, then run `make all` from the root directory of this repo. Note that the zip-files with the ADAMS data are locked with a password. If running the code below locally, replace `MYPASSWORD` with the password provided by HRS when you requested access to the ADAMS data.\n",
        "\n",
        "```\n",
        "git clone https://github.com/rmtrane/replication-of-gianattasio.git ./\n",
        "\n",
        "cd replication-of-gianattasio/\n",
        "\n",
        "mkdir data/HRS-zips # put downloaded .zip files here\n",
        "\n",
        "make all password=MYPASSWORD\n",
        "```\n",
        "\n",
        "### Prepare the data from HRS\n",
        "\n",
        "#### Download appropriate files\n",
        "\n",
        "The following .zip files should be downloaded from the [HRS Data Downloads site](https://hrsdata.isr.umich.edu/data-products/) and placed in the `data/HRS-zips` folder. We include links to data pages with details for each set of files, and also direct links for download (file names formatted as `file.zip` will take you straight to download the given file). A login is needed to download the data.\n",
        "\n",
        "Note: make sure your browser does not automatically open files when downloaded. If .zip files are automatically opened, they will be unzipped, and not fit the patterns expected. (On Safari on macOS: got Settings -> General -> uncheck 'Open \"safe\" files after downloading'.)\n",
        "\n",
        "* HRS Survey Data:\n",
        "  - [1998 HRS Core](https://hrsdata.isr.umich.edu/data-products/1998-hrs-core): [`h98da.zip`](https://hrsdata.isr.umich.edu/data-file-download/5515) and [`h98sas.zip`](https://hrsdata.isr.umich.edu/data-file-download/5625)\n",
        "  - [2000 HRS Core](https://hrsdata.isr.umich.edu/data-products/2000-hrs-core): [`h00da.zip`](https://hrsdata.isr.umich.edu/data-file-download/5508) and [`h00sas.zip`](https://hrsdata.isr.umich.edu/data-file-download/5640)\n",
        "  - [2002 HRS Core](https://hrsdata.isr.umich.edu/data-products/2002-hrs-core): [`h02da.zip`](https://hrsdata.isr.umich.edu/data-file-download/5506) and [`h02sas.zip`](https://hrsdata.isr.umich.edu/data-file-download/5637)\n",
        "  - [2004 HRS Core](https://hrsdata.isr.umich.edu/data-products/2004-hrs-core): [`h04da.zip`](https://hrsdata.isr.umich.edu/data-file-download/5516) and [`h04sas.zip`](https://hrsdata.isr.umich.edu/data-file-download/5645)\n",
        "  - [2006 HRS Core](https://hrsdata.isr.umich.edu/data-products/2006-hrs-core): [`h06da.zip`](https://hrsdata.isr.umich.edu/data-file-download/9480) and [`h06sas.zip`](https://hrsdata.isr.umich.edu/data-file-download/9483)\n",
        "  - [2008 HRS Core](https://hrsdata.isr.umich.edu/data-products/2008-hrs-core): [`h08da.zip`](https://hrsdata.isr.umich.edu/data-file-download/5510) and [`h08sas.zip`](https://hrsdata.isr.umich.edu/data-file-download/5652)\n",
        "  - [2010 HRS Core](https://hrsdata.isr.umich.edu/data-products/2010-hrs-core): [`h10da.zip`](https://hrsdata.isr.umich.edu/data-file-download/9464) and [`h10sas.zip`](https://hrsdata.isr.umich.edu/data-file-download/9466)\n",
        "\n",
        "* RAND HRS Data:\n",
        "  - We need an older version of the RAND data, the so-called Version P. This can be found under [archived data versions](https://hrsdata.isr.umich.edu/data-products/rand-hrs-archived-data-products).<br>\n",
        "    The file needed: \n",
        "        - RAND HRS Version P [`randhrsp_archive_SAS.zip`](https://hrsdata.isr.umich.edu/data-file-download/5414)\n",
        "\n",
        "* ADAMS Data:\n",
        "  - From the main HRS Data Downloads page, navigate to [HRS Sensitive Health Data](https://hrsdata.isr.umich.edu/data-products/sensitive-health). Note: additional permissions are needed to access this part of the data.<br>\n",
        "    The files to be downloaded are:\n",
        "      - [Wave A](https://hrsdata.isr.umich.edu/data-products/aging-demographics-and-memory-study-adams-wave): [adams1a.zip](https://hrsdata.isr.umich.edu/data-file-download/5539)\n",
        "      - [Wave B](https://hrsdata.isr.umich.edu/data-products/aging-demographics-and-memory-study-adams-wave-b): [adams1b.zip](https://hrsdata.isr.umich.edu/data-file-download/5616)\n",
        "      - [CrossWave](https://hrsdata.isr.umich.edu/data-products/aging-demographics-and-memory-study-adams-cross-wave-tracker-file): [adams1trk.zip](https://hrsdata.isr.umich.edu/data-file-download/5570) \n",
        "      \n",
        "* Hurd Probabilities:\n",
        "  - These are provided as a \"Contributed Project\" on the HRS website; follow [this direct link](https://hrsdata.isr.umich.edu/data-products/dementia-predicted-probabilities-files) to the page where the following zip file can be downloaded:\n",
        "    - [DementiaPredictedProbabilities.zip](https://hrsdata.isr.umich.edu/data-file-download/5578)\n",
        "\n",
        "#### Unzip all files (`make unzip_all password=MYPASSWORD`)\n",
        "\n",
        "All the `hXXXX.zip` files are in pairs: `hXXda.zip` and `hXXsas.zip`. Unzip each pair, and move the resulting folders to `data/HRS-unzips/hXX`. \n",
        "\n",
        "For the `adams1X.zip` files, unzip them and move the resulting folders to `data/HRS-unzips`. In each of the folders, you will find additional `.zip` files. Unzip the two called `adams1Xda.zip` and `adams1Xsas.zip`. Rename them to `da.zip` and `sas.zip`, respectively. \n",
        "\n",
        "For the `DementiaPredictedProbabilities.zip` and `randhrs_p_archive_SAS.zip` files, unzip them and move to `data/HRS-unzips/hurd` and `data/HRS-unzips/rand`, respectively. \n",
        "\n",
        "When completed, you should have a folder structure similar to what is illustrated below. I've excluded the files in the `da` and `sas` subfolders since there are a lot... We'll get back to these soon.\n",
        "\n",
        "```\n",
        "data/HRS-unzips\n",
        "├── a95\n",
        "│   ├── da\n",
        "│   └── sas\n",
        "├── adams1a\n",
        "│   ├── da\n",
        "│   └── sas\n",
        "├── adams1b\n",
        "│   ├── da\n",
        "│   └── sas\n",
        "├── adams1trk\n",
        "│   ├── da\n",
        "│   └── sas\n",
        "├── h00\n",
        "│   ├── da\n",
        "│   └── sas\n",
        "├── h02\n",
        "│   ├── da\n",
        "│   └── sas\n",
        "├── h04\n",
        "│   ├── da\n",
        "│   └── sas\n",
        "├── h06\n",
        "│   ├── da\n",
        "│   └── sas\n",
        "├── h08\n",
        "│   ├── da\n",
        "│   └── sas\n",
        "├── h10\n",
        "│   ├── da\n",
        "│   └── sas\n",
        "├── h96\n",
        "│   ├── da\n",
        "│   └── sas\n",
        "└── h98\n",
        "│   ├── da\n",
        "│   └── sas\n",
        "├── hurd\n",
        "│   ├── DescriptionOfPredictedProbabilities.pdf\n",
        "│   ├── pdem_withvarnames.dta\n",
        "│   └── pdem_withvarnames.sas7bdat\n",
        "└── rand\n",
        "    ├── ArchiveREADME.pdf\n",
        "    ├── incwlth_p.sas7bdat\n",
        "    ├── randhrs_P.pdf\n",
        "    ├── randiwp.pdf\n",
        "    ├── rndhrs_p.sas7bdat\n",
        "    └── sasfmts.sas7bdat\n",
        "```\n",
        "\n",
        "#### Update SAS scripts (`make .update_all_sas`)\n",
        "\n",
        "Ultimately, we need to run a bunch of SAS scripts that take `.da` files and create `.sas7bdat` files for later use. All the SAS files we need to run are in the `HRS-unzips/*/sas/` folders. Before we can run them, we need to update the some paths. \n",
        "\n",
        "Take, as an example, the file `data/HRS-unzips/h98/sas/h98a_r.sas`. This file is about 300 lines long, but the essence of the file is included below. It essentially extracts the data needed from the data file `data/HRS-unzips/h98/da/h98a_r.da`, and saves it to a new data set. \n",
        "\n",
        "```\n",
        "libname EXTRACT 'c:\\hrs1998\\sas\\' ; \n",
        "\n",
        "DATA EXTRACT.H98A_R;\n",
        "INFILE 'c:\\hrs1998\\data\\H98A_R.DA'  LRECL=192; \n",
        "\n",
        "INPUT \n",
        "  ... specify input columns...\n",
        ";\n",
        "\n",
        "\n",
        "LABEL\n",
        "  ... variable labels...\n",
        ";\n",
        "\n",
        "run;\n",
        "\n",
        "DATA EXTRACT.H98A_R;\n",
        "SET  EXTRACT.H98A_R;\n",
        "FORMAT \n",
        "  ... formatting of variables...\n",
        ";\n",
        "run;\n",
        "\n",
        "```\n",
        "\n",
        "To be able to run this SAS file, we need to fix the file paths. Set the `libname EXTRACT` to the folder `data/SAS/HRS/`, but include the full path. Also, fix the path to the input data file. In the end, the beginning of the file should look like this:\n",
        "\n",
        "```\n",
        "libname EXTRACT '/path/to/root/folder/data/SAS/HRS/';\n",
        "\n",
        "DATA EXTRACT.H98A_R;\n",
        "INFILE '/path/to/root/folder/data/HRS-unzips/h98/da/h98a_r.da' LRECL=192;\n",
        "```\n",
        "\n",
        "The rest of the file remains unchanged. Save this file to a new folder `data/HRS-unzips/h98/new_sas`. Repeat with all SAS files in the `data/HRS-unzips/h*` folders.\n",
        "\n",
        "For the SAS files in `data/HRS-unzips/adams1*/sas`, change the libname paths to `/path/to/root/folder/data/SAS/ADAMS`.\n",
        "\n",
        "#### Run SAS scripts (`make .run_all_sas`)\n",
        "\n",
        "Once we have created updated SAS files, we need to run them all. Before doing so, make sure you've created the folders `data/SAS/HRS` and `data/SAS/ADAMS`. \n",
        "\n",
        "Once you've run all SAS files, you will have a total of 304 `.sas7bdat` files in `data/SAS/HRS` and 29 `.sas7bdat` files in `data/SAS/ADAMS`.\n",
        "\n",
        "#### Prepare RAND data (`make data/SAS/rand/formats.sas7bcat`)\n",
        "\n",
        "To prepare the RAND data, we copy `rndhrs_p.sas7bdat` and `sasfmts.sas7bdat` from `data/HRS-unzips/rand` to `data/SAS/rand`. We then create `data/SAS/rand/formats.sas7bcat` using the following SAS scripts:\n",
        "\n",
        "```\n",
        "libname library '/path/to/root/folder/data/SAS/rand';\n",
        "  proc format library=library cntlin=library.sasfmts;\n",
        "run;\n",
        "```\n",
        "\n",
        "#### Prepare HURD data (`make data/SAS/created/hurdprobabilities_wide.csv`)\n",
        "\n",
        "The probabilities included from `data/HRS-unzips/hurd/pdem_withvarnames.sas7bdat` need to be in a wide format for the SAS files from [`powerepilab/AD_algorithm_comparison`](https://github.com/powerepilab/AD_algorithm_comparison) to be able to use them. The R-script can be run from the root folder to create an appropriate .csv file.\n",
        "\n",
        "\n",
        "```{r}\n",
        "library(tidyr)\n",
        "\n",
        "haven::read_sas('data/HRS-unzips/hurd/pdem_withvarnames.sas7bdat') %>% \n",
        "  pivot_wider(\n",
        "    names_from = prediction_year, \n",
        "    values_from = prob_dementia, \n",
        "    names_prefix = 'hurd_prob_'\n",
        "  ) %>% \n",
        "  readr::write_csv('data/SAS/created/hurdprobabilities_wide.csv', na = '.')\n",
        "```\n",
        "\n",
        "\n",
        "Note: the files from [`powerepilab/AD_algorithm_comparison`](https://github.com/powerepilab/AD_algorithm_comparison) rely on a dataset similar to the .csv file created here, but since my SAS skills a lacking a bit, I wasn't able to create this in SAS. Instead, we will modify the SAS scripts later to read in the probabilities from this .csv file.\n",
        "\n",
        "### Prepare SAS scripts to create training and validation data\n",
        "\n",
        "We now have all the data ready to create the training and validation data sets used in @gianattasioComparisonMethodsAlgorithmic2019. Now, we will prepare the SAS scripts that will eventually create the two data sets.\n",
        "\n",
        "#### Download from [`powerepilab/AD_algorithm_comparison`](https://github.com/powerepilab/AD_algorithm_comparison) (`make AD_algorithm_comparison/touch`)\n",
        "\n",
        "Clone the github repo into a new folder in your root directory. Call this folder `AD_algorithm_comparison`. To make sure no new changes have been pushed to the repo, you can check out the commit I used when creating this. To do so, run the following command from inside the `AD_algorithm_comparison` folder.\n",
        "\n",
        "```\n",
        "git reset --hard 1338e71\n",
        "```\n",
        "\n",
        "You should now see the following files in the folder `AD_algorithm_comparison`\n",
        "\n",
        "```\n",
        "AD_algorithm_comparison/\n",
        "├── 1a. Extract self-response variables from RANDp _ 2018.01.17.sas\n",
        "├── 1b. Extract proxy variables from core HRS _ 2018.01.17.sas\n",
        "├── 2. Create lags,leads, merge with ADAMS, set up regression vars _ 2018.01.17.sas\n",
        "├── 3. Assign algorithmic dementia diagnoses and create HRSt HRSv datasets_ 2018.03.02.sas\n",
        "├── Construct dataset of existing algorithm classifications for waves 2000-2014_2020_0110.sas\n",
        "└── README.md\n",
        "```\n",
        "\n",
        "#### Adjust SAS scripts (`make updated_AD_algorithm_comparison/touch`)\n",
        "\n",
        "As with the previous SAS scripts, we also need to adjust the paths in the SAS scripts just downloaded. \n",
        "\n",
        "For the file `AD_algorithm_comparison/1a. Extract self-response variables from RANDp _ 2018.01.17.sas`, change the beginning from \n",
        "\n",
        "```\n",
        "libname adams 'F:\\power\\HRS\\ADAMS Wave A';\n",
        "libname atrk 'F:\\power\\HRS\\ADAMS CrossWave';\n",
        "libname x 'F:\\power\\HRS\\DerivedData\\AD_Disparities_AlgorithmDev\\Data 2018_0105'; /*derived hrs files*/\n",
        "libname hrs 'F:\\power\\HRS\\HRS data (raw)\\SAS datasets'; /*raw hrs files, including Hurd probabilities*/\n",
        "libname rand 'F:\\power\\HRS\\RAND_HRS\\sasdata';\n",
        "```\n",
        "\n",
        "to\n",
        "\n",
        "```\n",
        "libname adams 'path/to/root/folder/data/SAS/ADAMS';\n",
        "libname atrk 'path/to/root/folder/data/SAS/ADAMS';\n",
        "libname x 'path/to/root/folder/data/SAS/created';\n",
        "libname hrs 'path/to/root/folder/data/SAS/HRS';\n",
        "libname rand 'path/to/root/folder/data/SAS/rand';\n",
        "```\n",
        "\n",
        "and save the updated file as `updated_AD_algorithm_comparison/1a_extract_self_response_variables.sas`.\n",
        "\n",
        "For `AD_algorithm_comparison/1b.  Extract proxy variables from core HRS _ 2018.01.17.sas`, change the line \n",
        "```\n",
        "%include \"F:\\power\\HRS\\Projects\\Ad_Disparities_AlgorithmDev\\SAS Programs\\Code_2018_0117\\1a. Extract self-response variables from RANDp _ 2018.01.17.sas\";\n",
        "```\n",
        "to\n",
        "```\n",
        "%include \"/path/to/root/folder/updated_AD_algorithm_comparison/1a_extact_self_response_variables.sas\";\n",
        "```\n",
        "We also need to make sure we keep the Vice President variable that is (later used for Table 1)[#checks]\n",
        "\n",
        "### Create training and validation data\n",
        "\n",
        "## Checks\n",
        "\n",
        "To make sure everything worked as intended, we recreate Table 1 of @gianattasioComparisonMethodsAlgorithmic2019. \n",
        "\n",
        "<details>\n",
        "\n",
        "<summary>R code for recreating Table 1</summary>\n",
        "\n",
        "First, the used libraries and reading in the data that was created from the SAS.\n",
        "\n",
        "\n",
        "```{r}\n",
        "library(tidyverse)\n",
        "library(gt)\n",
        "library(gtsummary)\n",
        "\n",
        "hrs_training <- haven::read_sas(here::here(\"data/SAS/created/hrst_2018_0302.sas7bdat\"))\n",
        "hrs_validation <- haven::read_sas(here::here(\"data/SAS/created/hrsv_2018_0302.sas7bdat\"))\n",
        "\n",
        "master_ad <- haven::read_sas(here::here(\"data/SAS/created/master_ad_2018_0117.sas7bdat\"))\n",
        "```\n",
        "\n",
        "\n",
        "Lots of the predictors are not present in the `hrs_training` and `hrs_validation` data, but rather included in the `master_ad` data. So, we add the predictors to the data sets. \n",
        "\n",
        "For the training data, this is straightforward, since all training data is from the ADAMS Wave A data set.\n",
        "\n",
        "\n",
        "```{r}\n",
        "hrs_training <- left_join(\n",
        "    hrs_training,\n",
        "    master_ad %>% \n",
        "      select(\n",
        "        HHID, \n",
        "        PN, \n",
        "        iadl = iadl5_A,\n",
        "        adl = adl5_A,\n",
        "        iqcode = iqcode_A,\n",
        "        jorm_symptoms = jorm5symp_A,\n",
        "        pr_memsc = pr_memsc1_A,\n",
        "        iwercog = iwercog_A,\n",
        "        immediate_word_recall = iword_A,\n",
        "        delayed_word_recall = dword_A,\n",
        "        serial7 = serial7_A,\n",
        "        dates = dates_A,\n",
        "        cactus = cact_A,\n",
        "        scissors = scis_A,\n",
        "        president = pres_A,\n",
        "        vp = vp_A,\n",
        "        count = ticscount1or2_A\n",
        "      )\n",
        "  ) %>% \n",
        "    mutate(dataset = 'Training')\n",
        "```\n",
        "\n",
        "\n",
        "For the validation data, it is a bit more complicated. Here, we need to pull the correct ADAMS wave for each row of the validation data. \n",
        "\n",
        "\n",
        "```{r}\n",
        "hrs_validation <- hrs_validation %>% \n",
        "  left_join(\n",
        "    master_ad %>% \n",
        "      select(\n",
        "        HHID, \n",
        "        PN, \n",
        "        matches(\"^iadl5_[BCD]$\"),\n",
        "        matches(\"^adl5_[BCD]$\"),\n",
        "        matches(\"^iqcode_[BCD]$\"),\n",
        "        matches(\"^jorm5symp_[BCD]$\"),\n",
        "        matches(\"^pr_memsc1_[BCD]$\"),\n",
        "        matches(\"^iwercog_[BCD]$\"),\n",
        "        matches(\"^iword_[BCD]$\"),\n",
        "        matches(\"^dword_[BCD]$\"),\n",
        "        matches(\"^serial7_[BCD]$\"),\n",
        "        matches(\"^dates_[BCD]$\"),\n",
        "        matches(\"^cact_[BCD]$\"),\n",
        "        matches(\"^scis_[BCD]$\"),\n",
        "        matches(\"^pres_[BCD]$\"),\n",
        "        matches(\"^vp_[BCD]$\"),\n",
        "        matches(\"^ticscount1or2_[BCD]$\")\n",
        "      ) %>% \n",
        "      rename_with(\n",
        "        .fn = \\(x) str_remove(x, '_'),\n",
        "        .cols = matches(\"^pr_memsc1_[BCD]$\")\n",
        "      ) %>% \n",
        "      pivot_longer(\n",
        "        cols = matches(\"_[BCD]$\"),\n",
        "        names_to = c(\".value\", \"ADAMSwave\"),\n",
        "        names_sep = \"_\",\n",
        "      ) %>% \n",
        "      rename(\n",
        "        iadl = iadl5,\n",
        "        adl = adl5,\n",
        "        jorm_symptoms = jorm5symp,\n",
        "        pr_memsc = prmemsc1,\n",
        "        immediate_word_recall = iword,\n",
        "        delayed_word_recall = dword,\n",
        "        cactus = cact,\n",
        "        scissors = scis,\n",
        "        president = pres,\n",
        "        count = ticscount1or2\n",
        "      ) %>% \n",
        "      mutate(\n",
        "        ADAMSwave = str_to_lower(ADAMSwave)\n",
        "      )\n",
        "  ) %>% \n",
        "  mutate(\n",
        "    dataset = 'Validation'\n",
        "  )\n",
        "```\n",
        "\n",
        "\n",
        "Finally, we recreate Table 1.\n",
        "\n",
        "\n",
        "```{r}\n",
        "## We use sjmisc::add_rows to preserve column labels. (dplyr::bind_rows removes labels.)\n",
        "table_1 <- sjmisc::add_rows(\n",
        "  hrs_training,\n",
        "  hrs_validation\n",
        ") %>% \n",
        "  select(\n",
        "    dement,\n",
        "    hrs_age,\n",
        "    proxy,\n",
        "    female,\n",
        "    edu_hurd,\n",
        "    raceeth4,\n",
        "    immediate_word_recall,\n",
        "    delayed_word_recall,\n",
        "    serial7,\n",
        "    dates,\n",
        "    cactus,\n",
        "    scissors,\n",
        "    president,\n",
        "    vp,\n",
        "    count,\n",
        "    iwercog,\n",
        "    pr_memsc,\n",
        "    iqcode,\n",
        "    jorm_symptoms,\n",
        "    adl, \n",
        "    iadl,\n",
        "    dataset\n",
        "  ) %>% \n",
        "  mutate(\n",
        "    ## Replace self-response for proxy that are 0 with NA\n",
        "    immediate_word_recall = if_else(proxy == 0, immediate_word_recall, NA),\n",
        "    delayed_word_recall = if_else(proxy == 0, delayed_word_recall, NA),\n",
        "  ) %>% \n",
        "  gtsummary::tbl_summary(\n",
        "    by = 'dataset',\n",
        "    statistic = list(all_continuous() ~ \"{mean} ({sd})\", all_categorical() ~ \"{n} ({p}%)\"),\n",
        "    type = list(\n",
        "      adl = 'continuous',\n",
        "      iadl = \"continuous\",\n",
        "      jorm_symptoms = \"continuous\",\n",
        "      pr_memsc = \"continuous\",\n",
        "      serial7 = 'continuous',\n",
        "      dates = 'continuous'\n",
        "    ),\n",
        "    digits = list(\n",
        "      all_continuous() ~ 1\n",
        "    )\n",
        "  ) %>% \n",
        "  modify_header(\n",
        "    label ~ \"**Outcomes and Predictors**\"\n",
        "  ) %>% \n",
        "  modify_footnote(\n",
        "    all_stat_cols() ~ NA\n",
        "  ) %>% \n",
        "  modify_spanning_header(\n",
        "    c(stat_1, stat_2) ~ \"**Mean (SD) or N (%)**\"\n",
        "  ) %>% \n",
        "  modify_table_body(\n",
        "    mutate,\n",
        "    groupname_col = case_match(\n",
        "      variable,\n",
        "      'dement' ~ 'Dementia Outcomes',\n",
        "      c(\"hrs_age\", \"proxy\", \"female\", \"edu_hurd\", \"raceeth4\") ~ 'Demographics',\n",
        "      c('immediate_word_recall', 'delayed_word_recall', 'serial7', \n",
        "        'dates', 'cactus', 'scissors', 'president', 'vp', 'count') ~ 'Cognition (self-response)',\n",
        "      c(\"iwercog\", \"pr_memsc\", \"iqcode\", \"jorm_symptoms\") ~ 'Cognition (proxy)',\n",
        "      c('adl', 'iadl') ~ 'Physical functioning limitations'\n",
        "    )\n",
        "  ) %>% \n",
        "  modify_column_indent(\n",
        "    columns = label,\n",
        "    rows = row_type %in% 'label',\n",
        "    indent = 4L\n",
        "  ) %>% \n",
        "  modify_column_indent(\n",
        "    columns = label,\n",
        "    rows = !row_type %in% 'label',\n",
        "    indent = 8L\n",
        "  ) %>% \n",
        "  as_gt() %>%\n",
        "  cols_width(\n",
        "    label ~ px(550)\n",
        "  ) %>% \n",
        "  tab_options(\n",
        "    row_group.font.weight = \"500\",\n",
        "    row_group.background.color = 'white'\n",
        "  ) \n",
        "```\n",
        "\n",
        "\n",
        "</details>\n",
        "\n",
        "A few things to note about the table below:\n",
        "\n",
        "* Some rows indicate that there are a number of \"unknown\" (or missing) values. For the variables in the \"Cognition (self-response)\" group, those who were evaluated by proxy are excluded. Therefore, unknown = number of proxy cases. For \"Cognition (proxy)\", unknown = number of NOT proxy cases. \n",
        "* There is a mistake in the label for the `delayed word recall` variable: this is in fact on a scale from 0 to 10, not 0 to 1. \n",
        "* The proxy rated memory score is for some reason on a scale of 0 to 4, whereas in Table 1 of @gianattasioComparisonMethodsAlgorithmic2019 it is on a scale from 1 to 5. Simply add 1 to the means, and we see that they match.\n",
        "\n",
        "<style>\n",
        "tr.even {background-color: white;}\n",
        "</style>\n",
        "\n",
        "\n",
        "```{r}\n",
        "#| output: asis\n",
        "table_1\n",
        "```"
      ],
      "id": "841c1215"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}